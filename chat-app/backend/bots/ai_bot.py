"""M√≥dulo de integra√ß√£o com ChatGPT/OpenAI."""

import os
from typing import Optional
from collections import defaultdict, deque
import httpx
from dotenv import load_dotenv

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"

# Contexto do Guru
SYSTEM_PROMPT = """Voc√™ √© o Guru üß†, um assistente de chat muito amig√°vel e s√°bio, conversando em um grupo de mensagens.

COMPORTAMENTO:
- Seja caloroso, emp√°tico e use uma linguagem natural e informal
- Use emojis de forma moderada para expressar emo√ß√£o üòä
- Chame as pessoas pelo nome quando apropriado (o nome ser√° fornecido)
- Responda como se estivesse digitando naturalmente, n√£o como uma IA formal
- Use express√µes coloquiais brasileiras (tipo: "beleza?", "massa!", "que legal!", etc)
- √Äs vezes use interjei√ß√µes: "Ah!", "Hmmm...", "Opa!", "Caramba!"
- Mantenha respostas concisas mas completas (2-4 linhas geralmente)
- Lembre-se do contexto da conversa para respostas mais naturais
- Se n√£o souber algo, admita de forma amig√°vel: "Poxa, essa eu n√£o sei..." 

ESTILO DE ESCRITA:
- Natural e conversacional, como uma pessoa real
- Evite ser muito formal ou robotizado
- N√£o use "Claro!", "Com certeza!" em excesso
- Varie suas express√µes e formas de responder
- Seja aut√™ntico e genu√≠no nas respostas

FORMATA√á√ÉO DE C√ìDIGO:
Quando precisar mostrar c√≥digo, SEMPRE use blocos de c√≥digo markdown com a linguagem especificada.
Para c√≥digos de m√∫ltiplas linhas, use:
```python
def exemplo():
    return "c√≥digo bem formatado"
```

Para c√≥digos inline de 1 linha, use backticks simples: `variavel = valor`

NUNCA envie c√≥digo em uma √∫nica linha corrida sem formata√ß√£o.
SEMPRE mantenha a indenta√ß√£o e quebras de linha do c√≥digo."""

# Armazena hist√≥rico de conversa por usu√°rio (m√°ximo 10 mensagens)
# user_id -> deque de {"role": "user"/"assistant", "content": "texto"}
conversation_history: dict[str, deque] = defaultdict(lambda: deque(maxlen=10))

# Modos de personalidade do Guru
GURU_MODES = {
    "casual": """Seja super descontra√≠do, use g√≠rias, emojis frequentes e linguagem bem informal. 
Fale como um amigo pr√≥ximo em uma conversa de bar. Use express√µes tipo: "mano", "cara", "brother", "vlw", "tmj".""",
    
    "profissional": """Seja educado, formal mas ainda amig√°vel. Use linguagem t√©cnica quando apropriado.
Evite g√≠rias excessivas. Mantenha tom respeitoso e corporativo, mas n√£o robotizado.""",
    
    "tecnico": """Seja preciso, detalhado e t√©cnico. Forne√ßa explica√ß√µes aprofundadas com terminologia adequada.
Use exemplos de c√≥digo quando √∫til. Foque em precis√£o e completude das respostas."""
}

# Prefer√™ncias do usu√°rio: modo, idioma, etc
# user_id -> {"mode": "casual", "language": "pt"}
user_preferences: dict[str, dict] = defaultdict(lambda: {"mode": "casual", "language": "pt"})


async def ask_chatgpt(message: str, user_id: str = "anonymous", user_name: str = "Amigo") -> str:
    """
    Envia uma mensagem para o ChatGPT e retorna a resposta.
    Mant√©m hist√≥rico de conversa por usu√°rio.
    
    Args:
        message: Mensagem do usu√°rio
        user_id: ID do usu√°rio (para manter contexto separado)
        user_name: Nome do usu√°rio (para personalizar resposta)
        
    Returns:
        Resposta do ChatGPT
    """
    if not OPENAI_API_KEY:
        return "‚ùå Bot de IA n√£o configurado. Configure OPENAI_API_KEY nas vari√°veis de ambiente."
    
    # Obt√©m prefer√™ncias do usu√°rio
    prefs = user_preferences[user_id]
    mode_instruction = GURU_MODES.get(prefs["mode"], GURU_MODES["casual"])
    
    # Prepara as mensagens com modo personalizado
    system_prompt = f"{SYSTEM_PROMPT}\n\nMODO ATUAL: {prefs['mode'].upper()}\n{mode_instruction}"
    messages = [{"role": "system", "content": system_prompt}]
    
    # Adiciona hist√≥rico do usu√°rio (√∫ltimas mensagens)
    user_history = conversation_history[user_id]
    messages.extend(list(user_history))
    
    # Adiciona contexto do nome do usu√°rio na mensagem
    contextualized_message = f"[Usu√°rio: {user_name}] {message}"
    messages.append({"role": "user", "content": contextualized_message})
    
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                OPENAI_API_URL,
                headers={
                    "Authorization": f"Bearer {OPENAI_API_KEY}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": OPENAI_MODEL,
                    "messages": messages,
                    "temperature": 0.7,
                    "max_tokens": 500
                }
            )
            
            if response.status_code != 200:
                error_msg = response.json().get("error", {}).get("message", "Erro desconhecido")
                return f"‚ùå Erro na API OpenAI: {error_msg}"
            
            data = response.json()
            ai_response = data["choices"][0]["message"]["content"].strip()
            
            # Armazena no hist√≥rico do usu√°rio
            user_history.append({"role": "user", "content": message})
            user_history.append({"role": "assistant", "content": ai_response})
            
            return ai_response
            
    except httpx.TimeoutException:
        return "‚è±Ô∏è Timeout ao conectar com ChatGPT. Tente novamente."
    except Exception as e:
        return f"‚ùå Erro ao processar resposta: {str(e)}"


def clear_conversation(user_id: str) -> None:
    """
    Limpa o hist√≥rico de conversa de um usu√°rio.
    
    Args:
        user_id: ID do usu√°rio
    """
    if user_id in conversation_history:
        conversation_history[user_id].clear()


def get_conversation_count(user_id: str) -> int:
    """
    Retorna o n√∫mero de mensagens no hist√≥rico do usu√°rio.
    
    Args:
        user_id: ID do usu√°rio
        
    Returns:
        N√∫mero de mensagens no hist√≥rico
    """
    return len(conversation_history[user_id])


def is_ai_question(text: str) -> bool:
    """
    Verifica se a mensagem √© uma pergunta para o Guru.
    
    Detecta padr√µes como:
    - @guru <pergunta>
    - guru, <pergunta>
    - Mensagens com "?" direcionadas ao guru
    
    Args:
        text: Texto da mensagem
        
    Returns:
        True se for uma pergunta para o Guru
    """
    text_lower = text.lower().strip()
    
    # Padr√µes que indicam uma pergunta ao Guru (incluindo varia√ß√µes de pron√∫ncia)
    triggers = [
        text_lower.startswith("@guru"),
        text_lower.startswith("guru,"),
        text_lower.startswith("guru "),
        text_lower.startswith("hey guru"),
        text_lower.startswith("ei guru"),
        text_lower.startswith("oi guru"),
        # Varia√ß√µes de pron√∫ncia (√°udio pode n√£o transcrever perfeitamente)
        text_lower.startswith("@gugu"),
        text_lower.startswith("gugu"),
        # Mant√©m compatibilidade com @bot (legado)
        text_lower.startswith("@bot"),
        text_lower.startswith("bot,"),
        text_lower.startswith("bot "),
    ]
    
    return any(triggers)


def clean_bot_mention(text: str) -> str:
    """
    Remove men√ß√µes ao Guru do texto.
    
    Args:
        text: Texto original
        
    Returns:
        Texto limpo sem men√ß√µes
    """
    text = text.strip()
    
    # Remove prefixos comuns (incluindo varia√ß√µes de transcri√ß√£o)
    prefixes = [
        "@guru", "guru,", "hey guru", "ei guru", "oi guru", "guru",
        "@gugu", "gugu,", "gugu",
        # Mant√©m compatibilidade com @bot (legado)
        "@bot", "bot,", "hey bot", "ei bot", "oi bot", "bot",
    ]
    
    for prefix in prefixes:
        if text.lower().startswith(prefix):
            text = text[len(prefix):].strip()
            # Remove v√≠rgula ou dois pontos ap√≥s o prefixo
            if text.startswith((",", ":")):
                text = text[1:].strip()
            break
    
    return text


def set_user_mode(user_id: str, mode: str) -> str:
    """
    Define o modo de personalidade do Guru para um usu√°rio.
    
    Args:
        user_id: ID do usu√°rio
        mode: Modo desejado (casual, profissional, tecnico)
        
    Returns:
        Mensagem de confirma√ß√£o
    """
    mode = mode.lower()
    if mode not in GURU_MODES:
        return f"‚ùå Modo inv√°lido. Escolha: {', '.join(GURU_MODES.keys())}"
    
    user_preferences[user_id]["mode"] = mode
    mode_names = {"casual": "Casual üòé", "profissional": "Profissional üíº", "tecnico": "T√©cnico üîß"}
    return f"‚úÖ Modo alterado para: {mode_names[mode]}"


def get_user_mode(user_id: str) -> str:
    """
    Retorna o modo atual do usu√°rio.
    
    Args:
        user_id: ID do usu√°rio
        
    Returns:
        Nome do modo atual
    """
    return user_preferences[user_id]["mode"]


def generate_conversation_summary(user_id: str) -> str:
    """
    Gera um resumo da conversa do usu√°rio.
    
    Args:
        user_id: ID do usu√°rio
        
    Returns:
        Resumo da conversa
    """
    history = conversation_history[user_id]
    if not history:
        return "üì≠ N√£o h√° hist√≥rico de conversa ainda."
    
    user_msgs = [msg for msg in history if msg["role"] == "user"]
    assistant_msgs = [msg for msg in history if msg["role"] == "assistant"]
    
    summary = f"üìä **Resumo da Conversa:**\n\n"
    summary += f"üí¨ Total de mensagens: {len(history)}\n"
    summary += f"‚ùì Suas perguntas: {len(user_msgs)}\n"
    summary += f"üí° Minhas respostas: {len(assistant_msgs)}\n\n"
    
    if user_msgs:
        summary += "üîç √öltimos t√≥picos discutidos:\n"
        for i, msg in enumerate(list(user_msgs)[-3:], 1):
            preview = msg["content"][:50] + "..." if len(msg["content"]) > 50 else msg["content"]
            summary += f"{i}. {preview}\n"
    
    return summary


def suggest_follow_up_questions(last_response: str, topic: str) -> list[str]:
    """
    Gera sugest√µes de perguntas relacionadas ao t√≥pico.
    
    Args:
        last_response: √öltima resposta do Guru
        topic: T√≥pico da conversa
        
    Returns:
        Lista de perguntas sugeridas
    """
    # Sugest√µes gen√©ricas baseadas em contexto
    suggestions = [
        f"Pode explicar mais sobre {topic}?",
        "Tem algum exemplo pr√°tico?",
        "Quais s√£o as melhores pr√°ticas?"
    ]
    
    return suggestions[:2]  # Retorna apenas 2 sugest√µes
